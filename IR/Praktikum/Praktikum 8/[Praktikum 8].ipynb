{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a4ce40",
   "metadata": {},
   "source": [
    "# Praktikum 8 Probabilistic Information Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f32e6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank_bm25 in c:\\users\\yanto\\anaconda3\\envs\\ir_env\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\yanto\\anaconda3\\envs\\ir_env\\lib\\site-packages (from rank_bm25) (1.23.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1c357f",
   "metadata": {},
   "source": [
    "Okapi BM25 atau yang biasa disebut dengan BM25 dikembangkan oleh City University London dan\n",
    "berdasarkan pada model probabilistik dasar yang mengurutkan dokumen dalam urutan menurun\n",
    "terhadap nilai relevansi sebuah dokumen terhadap informasi yang dibutuhkan. BM25 meranking\n",
    "dokumen berdasarkan probabilitas dan menggunakan term frequency untuk meranking similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8f17f",
   "metadata": {},
   "source": [
    "### Menghitung Skor Relevansi BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c3ee38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def tokenisasi(text):\n",
    "    tokens = text.split(\" \")\n",
    "    return tokens\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "def stemming(text):\n",
    "    #Create Stemmer\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    \n",
    "    #stemming process\n",
    "    output = stemmer.stem(text)\n",
    "    return output\n",
    "    \n",
    "def stemming_sentence(text):\n",
    "    output = \"\"\n",
    "    for token in tokenisasi(text):\n",
    "        output = output + stemming(token) + \" \"\n",
    "    return output[:-1]\n",
    "\n",
    "doc_dict_raw = {}\n",
    "doc_dict_raw['doc1'] = \"pengembangan sistem informasi penjadwalan\"\n",
    "doc_dict_raw['doc2'] = \"pengembangan model analisis sentimen berita\"\n",
    "doc_dict_raw['doc3'] = \"analisis sistem input output\"\n",
    "doc_dict_raw['doc4'] = \"pengembangan sistem informasi akademik universitas\"\n",
    "doc_dict_raw['doc5'] = \"pengembangan sistem cari berita ekonomi\"\n",
    "doc_dict_raw['doc6'] = \"analisis sistem neraca nasional\"\n",
    "doc_dict_raw['doc7'] = \"pengembangan sistem informasi layanan statistik\"\n",
    "doc_dict_raw['doc8'] = \"pengembangan sistem pencarian skripsi di universitas\"\n",
    "doc_dict_raw['doc9'] = \"analisis sentimen publik terhadap pemerintah\"\n",
    "doc_dict_raw['doc10'] = \"pengembangan model klasifikasi sentimen berita\"\n",
    "\n",
    "doc_dict = {}\n",
    "for doc_id, doc in doc_dict_raw.items():\n",
    "    doc_dict[doc_id] = stemming_sentence(doc)\n",
    "\n",
    "tokenized_corpus = [tokenisasi(doc_dict[doc_id]) for doc_id in doc_dict]\n",
    "\n",
    "\n",
    "def querinisasi(query):\n",
    "    tokenized_query = tokenisasi(query)\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "#     print(\"Query '\" + query + \"' :\") \n",
    "#     print(doc_scores)\n",
    "    return(doc_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87297ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': 'kembang sistem informasi jadwal', 'doc2': 'kembang model analisis sentimen berita', 'doc3': 'analisis sistem input output', 'doc4': 'kembang sistem informasi akademik universitas', 'doc5': 'kembang sistem cari berita ekonomi', 'doc6': 'analisis sistem neraca nasional', 'doc7': 'kembang sistem informasi layan statistik', 'doc8': 'kembang sistem cari skripsi di universitas', 'doc9': 'analisis sentimen publik hadap perintah', 'doc10': 'kembang model klasifikasi sentimen berita'}\n"
     ]
    }
   ],
   "source": [
    "# print(tokenized_corpus)\n",
    "print(doc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44c51b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.18979771, 0.        , 0.36586252, 1.08030712, 0.33219419,\n",
       "       0.36586252, 2.89216154, 0.30420029, 0.        , 0.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skor Relevansi dalam Suatu Query Tertentu\n",
    "querinisasi(\"sistem informasi statistik\")\n",
    "# querinisasi(\"sistem\")\n",
    "# querinisasi(\"sistem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e167e1",
   "metadata": {},
   "source": [
    "### Fungsi mengembalikan top k dokumen dengan BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89acbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def exact_top_k_bm25(doc_dict, rank_score, k):\n",
    "    relevance_scores = {}\n",
    "    i = 0\n",
    "    for doc_id in doc_dict.keys():\n",
    "        relevance_scores[doc_id] = rank_score[i]\n",
    "        i = i + 1\n",
    "        \n",
    "#         sorted_value = OrderedDict(sorted(relevance_scores.items(), key=lambda x: x[1], reverse = True))\n",
    "#         top_k = {j: sorted_value[j] for j in list(sorted_value)[:k]}\n",
    "        \n",
    "        sorted_value = OrderedDict(sorted(relevance_scores.items(),key = lambda x:x[1], reverse = True))\n",
    "        top_k = {j : sorted_value[j] for j in list(sorted_value)[:k]}\n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8c0bb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc7': 2.892161541603838, 'doc1': 1.1897977081195452, 'doc4': 1.080307121482777}\n"
     ]
    }
   ],
   "source": [
    "top_3_bm25 = exact_top_k_bm25(doc_dict, querinisasi(\"sistem informasi statistik\"),3)\n",
    "print(top_3_bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "224a25e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc1': 1.1897977081195452,\n",
       " 'doc4': 1.080307121482777,\n",
       " 'doc7': 1.080307121482777}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_top_k(doc_dict, querinisasi(\"sistem informasi \"),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56db9878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc1': 0.3658625167174947,\n",
       " 'doc3': 0.3658625167174947,\n",
       " 'doc6': 0.3658625167174947}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_top_k(doc_dict, querinisasi(\"sistem\"),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ca4295",
   "metadata": {},
   "source": [
    "## Perhitungan dengan VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "263af8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kembang\n",
      "sistem\n",
      "informasi\n",
      "jadwal\n",
      "kembang\n",
      "model\n",
      "analisis\n",
      "sentimen\n",
      "berita\n",
      "analisis\n",
      "sistem\n",
      "input\n",
      "output\n",
      "kembang\n",
      "sistem\n",
      "informasi\n",
      "akademik\n",
      "universitas\n",
      "kembang\n",
      "sistem\n",
      "cari\n",
      "berita\n",
      "ekonomi\n",
      "analisis\n",
      "sistem\n",
      "neraca\n",
      "nasional\n",
      "kembang\n",
      "sistem\n",
      "informasi\n",
      "layan\n",
      "statistik\n",
      "kembang\n",
      "sistem\n",
      "cari\n",
      "skripsi\n",
      "di\n",
      "universitas\n",
      "analisis\n",
      "sentimen\n",
      "publik\n",
      "hadap\n",
      "perintah\n",
      "kembang\n",
      "model\n",
      "klasifikasi\n",
      "sentimen\n",
      "berita\n",
      "{'kembang': ['doc1', 'doc2', 'doc4', 'doc5', 'doc7', 'doc8', 'doc10'], 'sistem': ['doc1', 'doc3', 'doc4', 'doc5', 'doc6', 'doc7', 'doc8'], 'informasi': ['doc1', 'doc4', 'doc7'], 'jadwal': ['doc1'], 'model': ['doc2', 'doc10'], 'analisis': ['doc2', 'doc3', 'doc6', 'doc9'], 'sentimen': ['doc2', 'doc9', 'doc10'], 'berita': ['doc2', 'doc5', 'doc10'], 'input': ['doc3'], 'output': ['doc3'], 'akademik': ['doc4'], 'universitas': ['doc4', 'doc8'], 'cari': ['doc5', 'doc8'], 'ekonomi': ['doc5'], 'neraca': ['doc6'], 'nasional': ['doc6'], 'layan': ['doc7'], 'statistik': ['doc7'], 'skripsi': ['doc8'], 'di': ['doc8'], 'publik': ['doc9'], 'hadap': ['doc9'], 'perintah': ['doc9'], 'klasifikasi': ['doc10']}\n"
     ]
    }
   ],
   "source": [
    "#### Inverted Index\n",
    "vocab = []\n",
    "inverted_index = {}\n",
    "for doc_id, doc in doc_dict.items():\n",
    "    for token in tokenisasi(doc):\n",
    "        print(token)\n",
    "        if token not in vocab : \n",
    "            vocab.append(token)\n",
    "            inverted_index[token] = []\n",
    "        if token in inverted_index:\n",
    "            if doc_id not in inverted_index[token]:\n",
    "                inverted_index[token].append(doc_id)\n",
    "# print(\"\\nThis is Vocab :\")\n",
    "# print(vocab)\n",
    "# print(\"\\nThis is inverted Index : \")\n",
    "# for doc_id in inverted_index :\n",
    "#     print(doc_id + \" : \")\n",
    "#     print(inverted_index[doc_id])\n",
    "#     print(\"\\n\")\n",
    "print(inverted_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ba9eccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': {'kembang': 1, 'sistem': 1, 'informasi': 1, 'jadwal': 1, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc2': {'kembang': 1, 'sistem': 0, 'informasi': 0, 'jadwal': 0, 'model': 1, 'analisis': 1, 'sentimen': 1, 'berita': 1, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc3': {'kembang': 0, 'sistem': 1, 'informasi': 0, 'jadwal': 0, 'model': 0, 'analisis': 1, 'sentimen': 0, 'berita': 0, 'input': 1, 'output': 1, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc4': {'kembang': 1, 'sistem': 1, 'informasi': 1, 'jadwal': 0, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 1, 'universitas': 1, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc5': {'kembang': 1, 'sistem': 1, 'informasi': 0, 'jadwal': 0, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 1, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 1, 'ekonomi': 1, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc6': {'kembang': 0, 'sistem': 1, 'informasi': 0, 'jadwal': 0, 'model': 0, 'analisis': 1, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 1, 'nasional': 1, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc7': {'kembang': 1, 'sistem': 1, 'informasi': 1, 'jadwal': 0, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 1, 'statistik': 1, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc8': {'kembang': 1, 'sistem': 1, 'informasi': 0, 'jadwal': 0, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 1, 'cari': 1, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 1, 'di': 1, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc9': {'kembang': 0, 'sistem': 0, 'informasi': 0, 'jadwal': 0, 'model': 0, 'analisis': 1, 'sentimen': 1, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 1, 'hadap': 1, 'perintah': 1, 'klasifikasi': 0}, 'doc10': {'kembang': 1, 'sistem': 0, 'informasi': 0, 'jadwal': 0, 'model': 1, 'analisis': 0, 'sentimen': 1, 'berita': 1, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 1}}\n"
     ]
    }
   ],
   "source": [
    "# TF \n",
    "def termFrequencyInDoc(vocab, doc_dict):\n",
    "    tf_docs = {}\n",
    "    for doc_id  in doc_dict.keys():\n",
    "        tf_docs[doc_id] = {}\n",
    "    for word in vocab:\n",
    "        for doc_id, doc in doc_dict.items():\n",
    "            tf_docs[doc_id][word] = doc.count(word)\n",
    "    return (tf_docs)\n",
    "\n",
    "tf = termFrequencyInDoc(vocab, doc_dict)\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8f7cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF\n",
    "\n",
    "## WordDocument Count \n",
    "def wordDocFre(vocab, doc_dict):\n",
    "    df = {}\n",
    "    for word in vocab:\n",
    "        frq = 0\n",
    "        for doc in doc_dict.values():\n",
    "            if word in tokenisasi(doc):\n",
    "                frq = frq + 1\n",
    "        df[word] = frq\n",
    "    return (df)\n",
    "\n",
    "import numpy as np\n",
    "def inverseDocFre(vocab, doc_fre, length):\n",
    "    idf = {}\n",
    "    for word in vocab:\n",
    "        idf[word] =  1 + np.log((length +1) /(doc_fre[word]+1))\n",
    "    return(idf)\n",
    "idf = inverseDocFre(vocab,wordDocFre(vocab, doc_dict), len(doc_dict))\n",
    "# print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "425eb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF.IDF\n",
    "def tfidf(vocab, tf, idf_scr, doc_dict):\n",
    "    tf_idf_scr = {}\n",
    "    for doc_id in doc_dict.keys():\n",
    "        tf_idf_scr[doc_id] = {}\n",
    "    for word in vocab:\n",
    "        for doc_id, doc in doc_dict.items():\n",
    "            tf_idf_scr[doc_id][word] = tf[doc_id][word] * idf_scr[word]\n",
    "    return (tf_idf_scr)\n",
    "# print(tfidf(vocab, tf, idf, doc_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b7b307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term Freq \n",
    "query = \"sistem informasi statistik\"\n",
    "# query = \"sistem sentimen berita\"\n",
    "def termFrequency(vocab, query):\n",
    "    tf_query = {}\n",
    "    for word in vocab:\n",
    "        tf_query[word] = query.count(word)\n",
    "    return (tf_query)\n",
    "tf_query = termFrequency(vocab, query)\n",
    "# print(tf_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba08be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term - Query Matrix\n",
    "TQ = np.zeros((len(vocab),1))\n",
    "for word in vocab:\n",
    "    ind1 = vocab.index(word)\n",
    "    TQ[ind1][0] = tf_query[word] * idf[word]\n",
    "# print(TQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2add6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cosine_sim(vec1, vec2):\n",
    " \n",
    "    dot_prod = 0\n",
    "    for i,v in enumerate(vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "    return(dot_prod/(mag_1*mag_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5777067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(vocab, tf, idf_scr, doc_dict):\n",
    "    tf_idf_scr = {}\n",
    "    for doc_id in doc_dict.keys():\n",
    "        tf_idf_scr[doc_id] = {}\n",
    "    for word in vocab:\n",
    "        for doc_id, doc in doc_dict.items():\n",
    "            tf_idf_scr[doc_id][word] = tf[doc_id][word] * idf_scr[word]\n",
    "    return (tf_idf_scr)\n",
    "\n",
    "tf_idf = tfidf(vocab, termFrequencyInDoc(vocab, doc_dict), inverseDocFre(vocab, wordDocFre(vocab, doc_dict), len(doc_dict)), doc_dict)\n",
    "# print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9904967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term - Document Matrix\n",
    "TD = np.zeros((len(vocab), len(doc_dict)))\n",
    "for word in vocab:\n",
    "    for doc_id, doc in tf_idf.items():\n",
    "        ind1 = vocab.index(word)\n",
    "        ind2 = list(tf_idf.keys()).index(doc_id)\n",
    "        TD[ind1][ind2] = tf_idf[doc_id][word]\n",
    "# print(TD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "099147c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc7': 0.7689768599816609, 'doc1': 0.414904809442661, 'doc4': 0.35626622628022314}\n"
     ]
    }
   ],
   "source": [
    "# Menyimpan skor kemiripan dalam suatu list \n",
    "from collections import OrderedDict\n",
    "def exact_top_k_vsm(doc_dict, TD, q,k):\n",
    "    relevance_scores = {}\n",
    "    i = 0 \n",
    "    for doc_id in doc_dict.keys():\n",
    "        relevance_scores[doc_id] = cosine_sim(q, TD[:,i])\n",
    "        i  = i + 1\n",
    "    \n",
    "    sorted_value = OrderedDict(sorted(relevance_scores.items(),key = lambda x:x[1], reverse = True))\n",
    "    top_k = {j : sorted_value[j] for j in list(sorted_value)[:k]}\n",
    "    return top_k\n",
    "top_3_vsm = exact_top_k_vsm(doc_dict, TD, TQ[:, 0], 3)\n",
    "print(top_3_vsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be335630",
   "metadata": {},
   "source": [
    "## Perbandingan dengan VSM\n",
    "\n",
    "query = \"sistem informasi statistik\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda2fe09",
   "metadata": {},
   "source": [
    "#### BM 25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d2df7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc7': 2.892161541603838,\n",
       " 'doc1': 1.1897977081195452,\n",
       " 'doc4': 1.080307121482777}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_top_k_bm25(doc_dict, querinisasi(\"sistem informasi statistik\"),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d2a101",
   "metadata": {},
   "source": [
    "#### VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7c8fec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc7': 0.7689768599816609,\n",
       " 'doc1': 0.414904809442661,\n",
       " 'doc4': 0.35626622628022314}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_top_k_vsm(doc_dict, TD, TQ[:, 0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bdd41e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
