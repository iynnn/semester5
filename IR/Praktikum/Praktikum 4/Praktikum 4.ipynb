{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c266a2a",
   "metadata": {},
   "source": [
    "# MODUL 4: TERM WEIGHTING, VECTOR SPACE MODEL, DAN UKURAN KEMIRIPAN TEKS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82197b2",
   "metadata": {},
   "source": [
    "## A. Teks Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975c3c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['pengembangan', 'sistem', 'informasi', 'penjadwalan'],\n",
       " ['pengembangan', 'model', 'analisis', 'sentimen', 'berita'],\n",
       " ['pengembangan', 'analisis', 'sistem', 'input', 'output']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverted Index \n",
    "doc1_term = [\"pengembangan\", \"sistem\", \"informasi\", \"penjadwalan\"]\n",
    "doc2_term = [\"pengembangan\", \"model\", \"analisis\", \"sentimen\", \"berita\"]\n",
    "doc3_term = [\"pengembangan\", \"analisis\", \"sistem\", \"input\", \"output\"]\n",
    "\n",
    "corpus_term = [doc1_term, doc2_term, doc3_term ]\n",
    "\n",
    "corpus_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eec6e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kembang': [1, 2, 3], 'sistem': [1, 3], 'informasi': [1], 'jadwal': [1], 'model': [2], 'analisis': [2, 3], 'sentimen': [2], 'berita': [2], 'input': [3], 'output': [3]}\n"
     ]
    }
   ],
   "source": [
    "inverted_index = {}\n",
    "\n",
    "\n",
    "\n",
    "def stemming(text):\n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "    # create stemmer\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    \n",
    "    output = stemmer.stem(text)\n",
    "    return(output)\n",
    "\n",
    "for i in range(len(corpus_term)):\n",
    "    for item in corpus_term[i]:\n",
    "        item = stemming(item)\n",
    "        if item not in inverted_index: # inputing item in dictionary if not available\n",
    "            inverted_index[item] = []\n",
    "        if (item in inverted_index) and ((i+1) not in inverted_index[item]): # setelah ada di key dictionary, masukin indeksnya ke berapa aja\n",
    "            inverted_index[item].append(i+1)\n",
    "print(inverted_index)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee015173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count raw term \n",
    "def termFrequencyInDoc(vocab, doc_dict):\n",
    "    tf_docs = {}\n",
    "    for doc_id  in doc_dict.keys():\n",
    "        tf_docs[doc_id] = {}\n",
    "    for word in vocab:\n",
    "        for doc_id, doc in doc_dict.items():\n",
    "            tf_docs[doc_id][word] = doc.count(word)\n",
    "    return (tf_docs)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096d51d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': {'kembang': 1, 'sistem': 1, 'informasi': 1, 'jadwal': 1, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0}, 'doc2': {'kembang': 1, 'sistem': 0, 'informasi': 0, 'jadwal': 0, 'model': 1, 'analisis': 1, 'sentimen': 1, 'berita': 1, 'input': 0, 'output': 0}, 'doc3': {'kembang': 0, 'sistem': 1, 'informasi': 0, 'jadwal': 0, 'model': 0, 'analisis': 1, 'sentimen': 0, 'berita': 0, 'input': 1, 'output': 1}}\n"
     ]
    }
   ],
   "source": [
    "vocab = list(inverted_index.keys()) # ini bisa ambil di pertemuan sebelumnya\n",
    "doc_dict = {}\n",
    "\n",
    "# clean after stemming \n",
    "doc_dict['doc1'] = \"kembang sistem informasi jadwal\"\n",
    "doc_dict['doc2'] = \"kembang model analisis sentimen berita\"\n",
    "doc_dict['doc3'] = \"analisis sistem input output\"\n",
    "\n",
    "\n",
    "print(termFrequencyInDoc(vocab, doc_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0729c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenn(doc):\n",
    "    token = doc.split(\" \")\n",
    "    return(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c2b502f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kembang': 2, 'sistem': 2, 'informasi': 1, 'jadwal': 1, 'model': 1, 'analisis': 2, 'sentimen': 1, 'berita': 1, 'input': 1, 'output': 1}\n"
     ]
    }
   ],
   "source": [
    "def wordDocFre(vocab, doc_dict):\n",
    "    df = {}\n",
    "    for word in vocab:\n",
    "        frq = 0\n",
    "        for doc in doc_dict.values():\n",
    "            if word in tokenn(doc):\n",
    "                frq = frq + 1\n",
    "        df[word] = frq\n",
    "    return (df)\n",
    "print(wordDocFre(vocab, doc_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b459174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def inverseDocFre(vocab, doc_fre, length):\n",
    "    idf = {}\n",
    "    for word in vocab:\n",
    "        idf[word] =  1 + np.log10((length +1) /(doc_fre[word]+1))\n",
    "    return(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d7fd76c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kembang': 1.1249387366083, 'sistem': 1.1249387366083, 'informasi': 1.3010299956639813, 'jadwal': 1.3010299956639813, 'model': 1.3010299956639813, 'analisis': 1.1249387366083, 'sentimen': 1.3010299956639813, 'berita': 1.3010299956639813, 'input': 1.3010299956639813, 'output': 1.3010299956639813}\n"
     ]
    }
   ],
   "source": [
    "print(inverseDocFre(vocab, wordDocFre(vocab, doc_dict), len(doc_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104e8b32",
   "metadata": {},
   "source": [
    "## B. Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51d5db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(vocab, tf, idf_scr, doc_dict):\n",
    "    tf_idf_scr = {}\n",
    "    for doc_id in doc_dict.keys():\n",
    "        tf_idf_scr[doc_id] = {}\n",
    "    for word in vocab:\n",
    "        for doc_id, doc in doc_dict.items():\n",
    "            tf_idf_scr[doc_id][word] = tf[doc_id][word] * idf_scr[word]\n",
    "    return (tf_idf_scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7236f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': {'kembang': 1.1249387366083, 'sistem': 1.1249387366083, 'informasi': 1.3010299956639813, 'jadwal': 1.3010299956639813, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0}, 'doc2': {'kembang': 1.1249387366083, 'sistem': 0.0, 'informasi': 0.0, 'jadwal': 0.0, 'model': 1.3010299956639813, 'analisis': 1.1249387366083, 'sentimen': 1.3010299956639813, 'berita': 1.3010299956639813, 'input': 0.0, 'output': 0.0}, 'doc3': {'kembang': 0.0, 'sistem': 1.1249387366083, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 1.1249387366083, 'sentimen': 0.0, 'berita': 0.0, 'input': 1.3010299956639813, 'output': 1.3010299956639813}}\n",
      "[[1.12493874 1.12493874 0.        ]\n",
      " [1.12493874 0.         1.12493874]\n",
      " [1.30103    0.         0.        ]\n",
      " [1.30103    0.         0.        ]\n",
      " [0.         1.30103    0.        ]\n",
      " [0.         1.12493874 1.12493874]\n",
      " [0.         1.30103    0.        ]\n",
      " [0.         1.30103    0.        ]\n",
      " [0.         0.         1.30103   ]\n",
      " [0.         0.         1.30103   ]]\n"
     ]
    }
   ],
   "source": [
    "tf_idf = tfidf(vocab, termFrequencyInDoc(vocab, doc_dict), inverseDocFre(vocab, wordDocFre(vocab, doc_dict), len(doc_dict)), doc_dict)\n",
    "print(tf_idf)\n",
    "\n",
    "# Term - Document Matrix\n",
    "TD = np.zeros((len(vocab), len(doc_dict)))\n",
    "for word in vocab:\n",
    "    for doc_id, doc in tf_idf.items():\n",
    "        ind1 = vocab.index(word)\n",
    "        ind2 = list(tf_idf.keys()).index(doc_id)\n",
    "        TD[ind1][ind2] = tf_idf[doc_id][word]\n",
    "print(TD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052b73fb",
   "metadata": {},
   "source": [
    "## C. Ukuran Kemiripan Teks _(Text Similarity)_\n",
    "### 1. Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c539b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(string1, string2):\n",
    "    if(len(string1) > len(string2)):\n",
    "        difference = len(string1) - len(string2)\n",
    "        string1[:difference]\n",
    "        n = len(string2)\n",
    "    elif len(string2) > len(string1):\n",
    "        difference = len(string2) - len(string1)\n",
    "        string2[:difference]\n",
    "        n = len(string1)\n",
    "    for i in range(n):\n",
    "        if string1[i] != string2[i]:\n",
    "            difference += 1\n",
    "    return (difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1258e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "31\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print(edit_distance(doc_dict['doc1'],doc_dict['doc2']))\n",
    "print(edit_distance(doc_dict['doc1'],doc_dict['doc3']))\n",
    "print(edit_distance(doc_dict['doc2'],doc_dict['doc3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79610e00",
   "metadata": {},
   "source": [
    "### 2. Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c459ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection)/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1766ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n",
      "0.14285714285714285\n",
      "0.125\n"
     ]
    }
   ],
   "source": [
    "print(jaccard_sim(doc_dict['doc1'].split(\" \"), doc_dict['doc2'].split(\" \")))\n",
    "print(jaccard_sim(doc_dict['doc1'].split(\" \"), doc_dict['doc3'].split(\" \")))\n",
    "print(jaccard_sim(doc_dict['doc2'].split(\" \"), doc_dict['doc3'].split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7729f3",
   "metadata": {},
   "source": [
    "### 3. Euclidian Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f15d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_dist(vec1, vec2):\n",
    "    # substring vector\n",
    "    temp = vec1 - vec2\n",
    "    \n",
    "    # doing dot product\n",
    "    # for finding \n",
    "    # sum of the square\n",
    "    sum_sq = np.dot(temp.T, temp)\n",
    "    \n",
    "    # Doing squareroot and\n",
    "    # printing Euclidian distance\n",
    "    return np.sqrt(sum_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b82ac287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3157758624989797\n",
      "3.049867295590651\n",
      "3.3157758624989797\n"
     ]
    }
   ],
   "source": [
    "print(euclidian_dist(TD[:,0], TD[:, 1])) # doc1 & doc2\n",
    "print(euclidian_dist(TD[:,0], TD[:, 2])) # doc1 & doc3\n",
    "print(euclidian_dist(TD[:,1], TD[:, 2])) # doc3 & doc3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf33543",
   "metadata": {},
   "source": [
    "### 4. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "431ce889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cosine_sim(vec1, vec2):\n",
    "#     vec1 = list(vec1)  # kenapa ini list object is not callable\n",
    "#     vec2 = list(vec2) \n",
    "    dot_prod = 0\n",
    "    for i,v in enumerate(vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "    return(dot_prod/(mag_1*mag_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d0317a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18861114004375698\n"
     ]
    }
   ],
   "source": [
    "print(cosine_sim(TD[:, 0], TD[:, 1])) # doc1 and doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02563df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
